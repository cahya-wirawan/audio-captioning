{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pathlib\n",
    "from typing import Optional, Any\n",
    "\n",
    "import transformers\n",
    "import wandb\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import typer\n",
    "import yaml\n",
    "import torchdata.datapipes as dp\n",
    "import json\n",
    "import time\n",
    "\n",
    "import audiocap.metrics\n",
    "import audiocap.data\n",
    "import audiocap.callbacks\n",
    "import audiocap.models\n",
    "\n",
    "from train_whisper_supervised import get_whisper_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May  3 16:13:37 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    59W / 400W |      2MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  Off  | 00000000:46:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    64W / 400W |  14688MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  Off  | 00000000:85:00.0 Off |                   On |\n",
      "| N/A   37C    P0    58W / 400W |   6190MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  Off  | 00000000:C7:00.0 Off |                   On |\n",
      "| N/A   61C    P0   200W / 400W |  39810MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro P1000        Off  | 00000000:C8:00.0 Off |                  N/A |\n",
      "| 36%   49C    P8    N/A /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  2    1   0   0  |   4689MiB / 40192MiB | 42      0 |  3   0    2    0    0 |\n",
      "|                  |      2MiB / 65535MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "|  2    2   0   1  |   1501MiB / 40192MiB | 42      0 |  3   0    2    0    0 |\n",
      "|                  |      2MiB / 65535MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "|  3    1   0   0  |     19MiB / 40192MiB | 42      0 |  3   0    2    0    0 |\n",
      "|                  |      0MiB / 65535MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "|  3    2   0   1  |  39791MiB / 40192MiB | 42      0 |  3   0    2    0    0 |\n",
      "|                  |      2MiB / 65535MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A   3351302      C   ...lcousins/.venv/bin/python     2475MiB |\n",
      "|    1   N/A  N/A   3383156      C   ...lcousins/.venv/bin/python    12211MiB |\n",
      "|    2    1    0    2193177      C   /usr/bin/python3                 4663MiB |\n",
      "|    2    2    0    2315224      C   python                           1475MiB |\n",
      "|    3    2    0    2014798      C   python                          39765MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "assert torch.cuda.is_available()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "DeferredCudaCallError",
     "evalue": "CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"../aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. \n\nCUDA call was originally invoked at:\n\n['  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\\n    app.launch_new_instance()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\\n    app.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\\n    self.io_loop.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\\n    self._run_once()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\\n    handle._run()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/events.py\", line 81, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\\n    await self.process_one()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\\n    await dispatch(*args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\\n    await result\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\\n    reply_content = await reply_content\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\\n    res = shell.run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\\n    result = self._run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\\n    result = runner(coro)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\\n    coro.send(None)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n', '  File \"/tmp/ipykernel_2317568/156268928.py\", line 8, in <module>\\n    import torch\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/__init__.py\", line 1146, in <module>\\n    _C._initExtension(manager_path())\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 197, in <module>\\n    _lazy_call(_check_capability)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 195, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:260\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     queued_call()\n\u001b[1;32m    261\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:145\u001b[0m, in \u001b[0;36m_check_capability\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(device_count()):\n\u001b[0;32m--> 145\u001b[0m     capability \u001b[39m=\u001b[39m get_device_capability(d)\n\u001b[1;32m    146\u001b[0m     major \u001b[39m=\u001b[39m capability[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:381\u001b[0m, in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Gets the cuda capability of a device.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[1;32m    371\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39m    tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m prop \u001b[39m=\u001b[39m get_device_properties(device)\n\u001b[1;32m    382\u001b[0m \u001b[39mreturn\u001b[39;00m prop\u001b[39m.\u001b[39mmajor, prop\u001b[39m.\u001b[39mminor\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:399\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid device id\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 399\u001b[0m \u001b[39mreturn\u001b[39;00m _get_device_properties(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"../aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()):\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mprint\u001b[39m(i, torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mget_device_properties(i))\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:395\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_device_properties\u001b[39m(device: _device_t) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    386\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Gets the properties of a device.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \n\u001b[1;32m    388\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[39m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m     _lazy_init()  \u001b[39m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    396\u001b[0m     device \u001b[39m=\u001b[39m _get_device_index(device, optional\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    397\u001b[0m     \u001b[39mif\u001b[39;00m device \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:264\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    262\u001b[0m             msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCUDA call failed lazily at initialization with error: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCUDA call was originally invoked at:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00morig_traceback\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 264\u001b[0m             \u001b[39mraise\u001b[39;00m DeferredCudaCallError(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     \u001b[39mdelattr\u001b[39m(_tls, \u001b[39m'\u001b[39m\u001b[39mis_initializing\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m: CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"../aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. \n\nCUDA call was originally invoked at:\n\n['  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\\n    app.launch_new_instance()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\\n    app.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\\n    self.io_loop.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\\n    self._run_once()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\\n    handle._run()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/events.py\", line 81, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\\n    await self.process_one()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\\n    await dispatch(*args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\\n    await result\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\\n    reply_content = await reply_content\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\\n    res = shell.run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\\n    result = self._run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\\n    result = runner(coro)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\\n    coro.send(None)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n', '  File \"/tmp/ipykernel_2317568/156268928.py\", line 8, in <module>\\n    import torch\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/__init__.py\", line 1146, in <module>\\n    _C._initExtension(manager_path())\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 197, in <module>\\n    _lazy_call(_check_capability)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 195, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(i, torch.cuda.get_device_properties(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "DeferredCudaCallError",
     "evalue": "CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"../aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. \n\nCUDA call was originally invoked at:\n\n['  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\\n    app.launch_new_instance()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\\n    app.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\\n    self.io_loop.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\\n    self._run_once()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\\n    handle._run()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/events.py\", line 81, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\\n    await self.process_one()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\\n    await dispatch(*args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\\n    await result\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\\n    reply_content = await reply_content\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\\n    res = shell.run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\\n    result = self._run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\\n    result = runner(coro)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\\n    coro.send(None)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n', '  File \"/tmp/ipykernel_2317568/156268928.py\", line 8, in <module>\\n    import torch\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/__init__.py\", line 1146, in <module>\\n    _C._initExtension(manager_path())\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 197, in <module>\\n    _lazy_call(_check_capability)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 195, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:260\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     queued_call()\n\u001b[1;32m    261\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:145\u001b[0m, in \u001b[0;36m_check_capability\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(device_count()):\n\u001b[0;32m--> 145\u001b[0m     capability \u001b[39m=\u001b[39m get_device_capability(d)\n\u001b[1;32m    146\u001b[0m     major \u001b[39m=\u001b[39m capability[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:381\u001b[0m, in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Gets the cuda capability of a device.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[1;32m    371\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39m    tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m prop \u001b[39m=\u001b[39m get_device_properties(device)\n\u001b[1;32m    382\u001b[0m \u001b[39mreturn\u001b[39;00m prop\u001b[39m.\u001b[39mmajor, prop\u001b[39m.\u001b[39mminor\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:399\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid device id\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 399\u001b[0m \u001b[39mreturn\u001b[39;00m _get_device_properties(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"../aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda:3\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m,], device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:264\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    262\u001b[0m             msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCUDA call failed lazily at initialization with error: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCUDA call was originally invoked at:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00morig_traceback\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 264\u001b[0m             \u001b[39mraise\u001b[39;00m DeferredCudaCallError(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     \u001b[39mdelattr\u001b[39m(_tls, \u001b[39m'\u001b[39m\u001b[39mis_initializing\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m: CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"../aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. \n\nCUDA call was originally invoked at:\n\n['  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\\n    app.launch_new_instance()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\\n    app.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\\n    self.io_loop.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\\n    self._run_once()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\\n    handle._run()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/events.py\", line 81, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\\n    await self.process_one()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\\n    await dispatch(*args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\\n    await result\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\\n    reply_content = await reply_content\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\\n    res = shell.run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\\n    result = self._run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\\n    result = runner(coro)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\\n    coro.send(None)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n', '  File \"/tmp/ipykernel_2317568/156268928.py\", line 8, in <module>\\n    import torch\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/__init__.py\", line 1146, in <module>\\n    _C._initExtension(manager_path())\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 197, in <module>\\n    _lazy_call(_check_capability)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 195, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "torch.tensor([1,2,3,], device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_checkpoint = pathlib.Path(\"../checkpoints/stoic-totem-29/checkpoint-18900\")\n",
    "dataset_dir = pathlib.Path(\"../../maratmp/audio-captioning/data/clotho_v2.1/audiofolder/\")\n",
    "output_dir = pathlib.Path(\"../inference_outputs\")\n",
    "generate_config = pathlib.Path(\"../configs/generate_clotho_test.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(generate_config, \"r\") as f:\n",
    "    generate_config_dict: dict = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run name:  stoic-totem-29\n"
     ]
    }
   ],
   "source": [
    "generate_args_dict = generate_config_dict[\"generate_args\"]\n",
    "architecture_config = generate_config_dict[\"architecture\"]\n",
    "architecture_name = architecture_config[\"name\"]\n",
    "use_pretrained_encoder = architecture_config[\"use_pretrained_whisper_encoder\"]\n",
    "use_pretrained_decoder = architecture_config[\"use_pretrained_whisper_decoder\"]\n",
    "\n",
    "only_allowed_tokens = generate_config_dict[\"only_allowed_tokens\"]\n",
    "batch_size = generate_config_dict[\"batch_size\"]\n",
    "\n",
    "data_config = generate_config_dict[\"data\"]\n",
    "dataset_name = data_config[\"dataset_name\"]\n",
    "task = data_config[\"task\"]\n",
    "dataset_type = data_config[\"dataset_type\"]\n",
    "data_limit = data_config[\"data_limit\"]\n",
    "run_name = load_checkpoint.parent.name  \n",
    "\n",
    "print(\"run name: \", run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trained parameters: 1543304960/1543304960 = 100.00%\n"
     ]
    }
   ],
   "source": [
    "config = transformers.WhisperConfig.from_pretrained(architecture_name)\n",
    "tokenizer = transformers.WhisperTokenizer.from_pretrained(architecture_name, language=\"en\", task=\"transcribe\")\n",
    "feature_extractor = transformers.WhisperFeatureExtractor.from_pretrained(architecture_name)\n",
    "collator = audiocap.data.DataCollatorAudioSeq2SeqWithPadding(tokenizer, feature_extractor)\n",
    "assert isinstance(config, transformers.WhisperConfig)\n",
    "model = get_whisper_model(architecture_name, config, load_checkpoint, use_pretrained_encoder, use_pretrained_decoder)\n",
    "\n",
    "tuned_params = sum(p.shape.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.shape.numel() for p in model.parameters())\n",
    "print(f\"Number of trained parameters: {tuned_params}/{total_params} = {tuned_params/total_params*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "DeferredCudaCallError",
     "evalue": "CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"../aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. \n\nCUDA call was originally invoked at:\n\n['  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\\n    app.launch_new_instance()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\\n    app.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\\n    self.io_loop.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\\n    self._run_once()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\\n    handle._run()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/events.py\", line 81, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\\n    await self.process_one()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\\n    await dispatch(*args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\\n    await result\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\\n    reply_content = await reply_content\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\\n    res = shell.run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\\n    result = self._run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\\n    result = runner(coro)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\\n    coro.send(None)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n', '  File \"/tmp/ipykernel_1951550/2518376201.py\", line 8, in <module>\\n    import torch\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/__init__.py\", line 1146, in <module>\\n    _C._initExtension(manager_path())\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 197, in <module>\\n    _lazy_call(_check_capability)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 195, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:260\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     queued_call()\n\u001b[1;32m    261\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:145\u001b[0m, in \u001b[0;36m_check_capability\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(device_count()):\n\u001b[0;32m--> 145\u001b[0m     capability \u001b[39m=\u001b[39m get_device_capability(d)\n\u001b[1;32m    146\u001b[0m     major \u001b[39m=\u001b[39m capability[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:381\u001b[0m, in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Gets the cuda capability of a device.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[1;32m    371\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39m    tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m prop \u001b[39m=\u001b[39m get_device_properties(device)\n\u001b[1;32m    382\u001b[0m \u001b[39mreturn\u001b[39;00m prop\u001b[39m.\u001b[39mmajor, prop\u001b[39m.\u001b[39mminor\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:399\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid device id\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 399\u001b[0m \u001b[39mreturn\u001b[39;00m _get_device_properties(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"../aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/transformers/modeling_utils.py:1811\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1807\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`.to` is not supported for `8-bit` models. Please use the model as it is, since the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1808\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1809\u001b[0m     )\n\u001b[1;32m   1810\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1811\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "File \u001b[0;32m~/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py:264\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    262\u001b[0m             msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCUDA call failed lazily at initialization with error: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCUDA call was originally invoked at:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00morig_traceback\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 264\u001b[0m             \u001b[39mraise\u001b[39;00m DeferredCudaCallError(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     \u001b[39mdelattr\u001b[39m(_tls, \u001b[39m'\u001b[39m\u001b[39mis_initializing\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m: CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"../aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. \n\nCUDA call was originally invoked at:\n\n['  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\\n    app.launch_new_instance()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\\n    app.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\\n    self.io_loop.start()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\\n    self._run_once()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\\n    handle._run()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/asyncio/events.py\", line 81, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\\n    await self.process_one()\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\\n    await dispatch(*args)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\\n    await result\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\\n    reply_content = await reply_content\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\\n    res = shell.run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\\n    result = self._run_cell(\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\\n    result = runner(coro)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\\n    coro.send(None)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n', '  File \"/tmp/ipykernel_1951550/2518376201.py\", line 8, in <module>\\n    import torch\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/__init__.py\", line 1146, in <module>\\n    _C._initExtension(manager_path())\\n', '  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 197, in <module>\\n    _lazy_call(_check_capability)\\n', '  File \"/home/xhajek9/miniconda3/envs/malach23/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 195, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']"
     ]
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set eval dataset\n",
    "audioset_dir = None\n",
    "audiocaps_dir = None\n",
    "clotho_dir = None\n",
    "\n",
    "if dataset_name == \"clotho\":\n",
    "    ds = audiocap.data.load_clotho(dataset_dir, tokenizer, feature_extractor, None, 0, 0, 0)\n",
    "elif dataset_name == \"audioset\":\n",
    "    ds = audiocap.data.load_audioset(dataset_dir, tokenizer, feature_extractor, None, 0, 0, 0)\n",
    "elif dataset_name == \"audiocaps\":\n",
    "    ds = audiocap.data.load_audiocaps(dataset_dir, tokenizer, feature_extractor, None, 0, 0, 0)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset name: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|startoftranscript|><|en|><|transcribe|><|notimestamps|>clotho > caption: Music plays nearby as a person sprays on a surface<|endoftext|>']\n",
      "['<|startoftranscript|><|en|><|transcribe|><|notimestamps|>clotho > caption: A large motor vehicle engine is running and vibrating<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "# generate captions (no filename)\n",
    "dataloader = DataLoader(ds[dataset_type].pipe, batch_size=1, collate_fn=collator, num_workers=4)\n",
    "all_predictions = []\n",
    "for i, batch in enumerate(dataloader):\n",
    "    if data_limit and i >= data_limit/batch_size:\n",
    "        break\n",
    "\n",
    "    prediction_ids = model.generate(batch[\"input_features\"], \n",
    "                                    forced_ac_decoder_ids=batch[\"forced_ac_decoder_ids\"], \n",
    "                                    **generate_args_dict)\n",
    "    predictions = tokenizer.batch_decode(prediction_ids, skip_special_tokens=False)\n",
    "    all_predictions.extend([{\"caption\": p} for p in enumerate(predictions)])\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'caption': (0,\n",
       "   '<|startoftranscript|><|en|><|transcribe|><|notimestamps|>clotho > caption: Music plays nearby as a person sprays on a surface<|endoftext|>')},\n",
       " {'caption': (0,\n",
       "   '<|startoftranscript|><|en|><|transcribe|><|notimestamps|>clotho > caption: A large motor vehicle engine is running and vibrating<|endoftext|>')}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate captions (filename, but bs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save predictions as jsonl to output_dir\n",
    "log_dir = output_dir / \"logs\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "timestamp = round(time.time())\n",
    "with open(output_dir / f\"{run_name}_{dataset_name}_{dataset_type}_{timestamp}.jsonl\", \"w\") as f:\n",
    "    for prediction in all_predictions:\n",
    "        f.write(json.dumps(prediction) + \"\\n\")\n",
    "\n",
    "# copy generate_config to log_dir\n",
    "generate_config_dst = log_dir / f\"{timestamp}.yaml\"\n",
    "generate_config_dst.write_text(generate_config.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|en|><|transcribe|><|notimestamps|>clotho > caption: A motor vehicle engine is running and vibrating, and people are talking in the background<|endoftext|>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mif\u001b[39;00m device\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mget_device_name(\u001b[39m0\u001b[39m))\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMemory Usage:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malach23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
