{
  "checkpoint": "../../maratmp/audio-captioning/checkpoints/dainty-yogurt-57/checkpoint-2600",
  "data": "../../maratmp/audio-captioning/data/clotho_v2.1/audiofolder/validation",
  "output_file": "../inference_outputs/dainty-yogurt-57_validation_predict_clotho_beam_multinomial10_topk3_config.csv",
  "recursive": false,
  "config_file": "../configs/hyperparameters_search/predict_clotho_beam_multinomial10_topk3_config.yaml",
  "take_first_n": null,
  "num_files": 200,
  "config": {
    "architecture": {
      "name": "openai/whisper-large-v2"
    },
    "runtime": {
      "use_fp16": true,
      "device": "cuda"
    },
    "dataloader": {
      "batch_size": 2,
      "num_workers": 4,
      "pin_memory": true
    },
    "generate": {
      "num_beams": 10,
      "do_sample": true,
      "top_k": 3,
      "max_length": 80
    },
    "dataset": {
      "source_ds": "clotho",
      "task": "caption"
    }
  },
  "cuda_visible_devices": "1",
  "command": "predict.py --checkpoint ../../maratmp/audio-captioning/checkpoints/dainty-yogurt-57/checkpoint-2600 --data ../../maratmp/audio-captioning/data//clotho_v2.1/audiofolder/validation --output-file ../inference_outputs/dainty-yogurt-57_validation_predict_clotho_beam_multinomial10_topk3_config.csv --config-file ../configs/hyperparameters_search/predict_clotho_beam_multinomial10_topk3_config.yaml",
  "wall_time": 125.13968539237976,
  "metric_computation": {
    "predictions file": "../inference_outputs/dainty-yogurt-57_validation_predict_clotho_beam_multinomial10_topk3_config.csv",
    "ground truth file": "../../maratmp/audio-captioning/data/clotho_v2.1/clotho_captions_validation.csv",
    "computed metrics": {
      "sacrebleu": 15.511702661574823,
      "meteor": 0.371446199192804,
      "spice": 0.13174151945953544,
      "cider": 0.4415741627024885,
      "spider": 0.286657841081012
    }
  }
}