{
  "checkpoint": "../../maratmp/audio-captioning/checkpoints/dainty-yogurt-57/checkpoint-2600",
  "data": "../../maratmp/audio-captioning/data/clotho_v2.1/audiofolder/validation",
  "output_file": "../inference_outputs/dainty-yogurt-57_validation_predict_clotho_beam_multinomial3_topk3_config.csv",
  "recursive": false,
  "config_file": "../configs/hyperparameters_search/predict_clotho_beam_multinomial3_topk3_config.yaml",
  "take_first_n": null,
  "num_files": 200,
  "config": {
    "architecture": {
      "name": "openai/whisper-large-v2"
    },
    "runtime": {
      "use_fp16": true,
      "device": "cuda"
    },
    "dataloader": {
      "batch_size": 2,
      "num_workers": 4,
      "pin_memory": true
    },
    "generate": {
      "num_beams": 3,
      "do_sample": true,
      "top_k": 3,
      "max_length": 80
    },
    "dataset": {
      "source_ds": "clotho",
      "task": "caption"
    }
  },
  "cuda_visible_devices": "1",
  "command": "predict.py --checkpoint ../../maratmp/audio-captioning/checkpoints/dainty-yogurt-57/checkpoint-2600 --data ../../maratmp/audio-captioning/data//clotho_v2.1/audiofolder/validation --output-file ../inference_outputs/dainty-yogurt-57_validation_predict_clotho_beam_multinomial3_topk3_config.csv --config-file ../configs/hyperparameters_search/predict_clotho_beam_multinomial3_topk3_config.yaml",
  "wall_time": 81.05399060249329,
  "metric_computation": {
    "predictions file": "../inference_outputs/dainty-yogurt-57_validation_predict_clotho_beam_multinomial3_topk3_config.csv",
    "ground truth file": "../../maratmp/audio-captioning/data/clotho_v2.1/clotho_captions_validation.csv",
    "computed metrics": {
      "sacrebleu": 15.55807161443736,
      "meteor": 0.3709841327966093,
      "spice": 0.13009291630903871,
      "cider": 0.44535737596954594,
      "spider": 0.28772514613929234
    }
  }
}