{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pathlib\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_root = pathlib.Path(\"/home/xhajek9/audio-captioning/submission/Kadlcik_JKU_task6a/task6\")\n",
    "submission_1 = submission_root / \"Kadlcik_JKU_task6a_1\"\n",
    "submission_2 = submission_root / \"Kadlcik_JKU_task6a_2\"\n",
    "submission_3 = submission_root / \"Kadlcik_JKU_task6a_3\"\n",
    "\n",
    "submissions = [submission_1, submission_2, submission_3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission 1 safely loaded\n",
      "submission 2 safely loaded\n",
      "submission 3 safely loaded\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "for i, submission in enumerate(submissions):\n",
    "    with open(submission / f\"Kadlcik_JKU_task6a_submission_{i+1}_metadata.yaml\", 'r') as file:\n",
    "        meta = yaml.safe_load(file)\n",
    "        print(f\"submission {i+1} safely loaded\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correct audiofiles in test and analysis predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1043 test files\n",
      "found 8360 analysis files\n"
     ]
    }
   ],
   "source": [
    "test_path = pathlib.Path(\"/home/xhajek9/maratmp/audio-captioning/data/submission/test\")\n",
    "analysis_path = pathlib.Path(\"/home/xhajek9/maratmp/audio-captioning/data/submission/clotho_analysis\")\n",
    "\n",
    "test_files = list((test_path).glob(\"*.wav\"))\n",
    "analysis_files = list(analysis_path.glob(\"*.wav\"))\n",
    "\n",
    "test_filenames = [f.name for f in test_files]\n",
    "analysis_filenames = [f.name for f in analysis_files]\n",
    "\n",
    "print(f\"found {len(test_files)} test files\")\n",
    "print(f\"found {len(analysis_files)} analysis files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load predictions\n",
    "for i, submission in enumerate(submissions):\n",
    "    testing_predictions = pd.read_csv(submission / f\"Kadlcik_JKU_task6a_submission_{i + 1}_testing_output.csv\")\n",
    "    analysis_predictions = pd.read_csv(submission / f\"Kadlcik_JKU_task6a_submission_{i + 1}_analysis_output.csv\")\n",
    "\n",
    "    # check uniquenes\n",
    "    assert len(testing_predictions) == len(testing_predictions.file_name.unique()), f\"testing predicitons {i+1} are not unique\"\n",
    "    assert len(analysis_predictions) == len(analysis_predictions.file_name.unique()), f\"analysis predicitons {i+1} are not unique\"\n",
    "\n",
    "    # check all files are present\n",
    "    assert set(testing_predictions.file_name) == set(test_filenames), f\"testing predicitons {i+1} are not complete\"\n",
    "    assert set(analysis_predictions.file_name) == set(analysis_filenames), f\"analysis predicitons {i+1} are not complete\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malach23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
