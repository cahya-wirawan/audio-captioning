{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = \"openai/whisper-tiny\"\n",
    "model = transformers.WhisperForConditionalGeneration.from_pretrained(model_str)\n",
    "\n",
    "feature_extractor = transformers.WhisperFeatureExtractor.from_pretrained(model_str)\n",
    "\n",
    "tokenizer = transformers.WhisperTokenizer.from_pretrained(\n",
    "    model_str,\n",
    "    language=\"en\", \n",
    "    task=\"transcribe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftranscript|>', '<|en|>', '<|transcribe|>', '<|notimestamps|>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(tokenizer.prefix_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load some data\n",
    "\n",
    "You might need to visit the dataset on HF and agree to the terms of use.\n",
    "Also, you need to login using huggingface cli to authenticate before loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_13 = datasets.load_dataset(\"mozilla-foundation/common_voice_13_0\", \"en\", split=\"train\", streaming=True, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 1013968it [00:25, 40092.05it/s]\n",
      "/var/tmp/xkadlci2/.conda/envs/audiocap/lib/python3.8/site-packages/datasets/features/audio.py:313: UserWarning: \n",
      "To support 'mp3' decoding with `torchaudio>=0.12.0`, please install `ffmpeg4` system package. On Google Colab you can run:\n",
      "\n",
      "\t!add-apt-repository -y ppa:jonathonf/ffmpeg-4 && apt update && apt install -y ffmpeg\n",
      "\n",
      "and restart your runtime. Alternatively, you can downgrade `torchaudio`:\n",
      "\n",
      "\tpip install \"torchaudio<0.12\"`.\n",
      "\n",
      "Otherwise 'mp3' files will be decoded with `librosa`.\n",
      "  warnings.warn(\n",
      "/var/tmp/xkadlci2/.conda/envs/audiocap/lib/python3.8/site-packages/datasets/features/audio.py:334: UserWarning: Decoding mp3 with `librosa` instead of `torchaudio`, decoding might be slow.\n",
      "  warnings.warn(\"Decoding mp3 with `librosa` instead of `torchaudio`, decoding might be slow.\")\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "batch = []\n",
    "for sample in cv_13:\n",
    "    batch.append(sample)\n",
    "    if len(batch) >= batch_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([104064])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_signal = torchaudio.functional.resample(\n",
    "    torch.tensor(sample[\"audio\"][\"array\"]),\n",
    "    sample[\"audio\"][\"sampling_rate\"],\n",
    "    16000,\n",
    ")\n",
    "label_str = sample[\"sentence\"]\n",
    "audio_signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_extractor(audio_signal, sampling_rate=16000, return_tensors=\"pt\")[\"input_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forced_prefix_decoded = '<|startoftranscript|><|en|><|transcribe|><|notimestamps|>This device' \n",
      "\n",
      "label_str = 'This device has a cathode inside an anode wire cage.'\n",
      "forced_prefix_str = 'This device'\n",
      "outputs_str = 'This device has a cathode inside an anode wire cage.'\n"
     ]
    }
   ],
   "source": [
    "#forced_prefix_str = \"This is a device that has\"\n",
    "forced_prefix_str = \"This device\"\n",
    "\n",
    "forced_prefix = tokenizer(text_target=forced_prefix_str, return_tensors=\"pt\")[\"input_ids\"]\n",
    "forced_prefix = forced_prefix[:, :-1] # remove EOS token, should be done in a better way\n",
    "forced_prefix_decoded = tokenizer.decode(forced_prefix[0], skip_special_tokens=False)\n",
    "print(f\"{forced_prefix_decoded = } \\n\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs=features,\n",
    "    decoder_input_ids=forced_prefix,\n",
    "    max_length=100,\n",
    "    num_beams=5,\n",
    "    do_sample=False,\n",
    ")[0]\n",
    "outputs_str = tokenizer.decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "print(f\"{label_str = }\")\n",
    "print(f\"{forced_prefix_str = }\")\n",
    "print(f\"{outputs_str = }\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, model worked well with the forced prefix.\n",
    "It caught up what part of audio was probably transcribed already and finished the remaining part."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This device has a cathode inside an anode wire cage.',\n",
       " 'This device has a cathode inside an anode wire cage.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trivial experiment\n",
    "\n",
    "batch_outputs = model.generate(\n",
    "    inputs=features.repeat(2, 1, 1),\n",
    "    decoder_input_ids=forced_prefix.repeat(2, 1),\n",
    "    max_length=100,\n",
    "    num_beams=5,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "tokenizer.batch_decode(batch_outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50257, 50257, 50258, 50259, 50359, 50363,  5723,  4302]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.tensor(tokenizer.pad_token_id).repeat(1, 2), forced_prefix], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD BEFORE FLUFF\n",
      "['<|endoftext|><|endoftext|><|startoftranscript|><|en|><|transcribe|><|notimestamps|>This device, is, is, is, is, is, is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is-is']\n",
      "\n",
      "PAD BETWEEN FLUFF AND PREFIX\n",
      "['<|startoftranscript|><|en|><|transcribe|><|notimestamps|><|endoftext|><|endoftext|>This device has a cathode inside an anode wire cage.<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "# Does the model work with padding in prefixes?\n",
    "\n",
    "# definitely not if the padding is before <fluff> - i.e:\n",
    "    # <PAD><PAD><PAD><|startoftranscript|><|en|><|transcribe|><|notimestamps|> <FORCED PREFIX>\n",
    "\n",
    "# Maybe if the padding is after <fluff> - i.e. \n",
    "    # <|startoftranscript|><|en|><|transcribe|><|notimestamps|><|PAD|><PAD><PAD> <FORCED PREFIX>\n",
    "    # but it seems like good idea to use the padding in the training if it's going to be there during .generate()\n",
    "    # even if it seems from this trivial experiment like the model can handle it during .generate()\n",
    "\n",
    "\n",
    "batch_outputs_1 = model.generate(\n",
    "    inputs=features,\n",
    "    decoder_input_ids=torch.cat([\n",
    "        torch.tensor(tokenizer.pad_token_id).repeat(1, 2),\n",
    "        forced_prefix,\n",
    "    ], dim=-1),\n",
    "    decoder_attention_mask=torch.cat([\n",
    "        torch.zeros(1, 2),\n",
    "        torch.ones_like(forced_prefix),\n",
    "    ], dim=-1),\n",
    "    max_length=100,\n",
    "    num_beams=5,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "print(\"PAD BEFORE FLUFF\")\n",
    "print(tokenizer.batch_decode(batch_outputs_1, skip_special_tokens=False))\n",
    "print()\n",
    "\n",
    "\n",
    "batch_outputs_2 = model.generate(\n",
    "    inputs=features,\n",
    "    decoder_input_ids=torch.cat([\n",
    "        forced_prefix[:, :4],\n",
    "        torch.tensor(tokenizer.pad_token_id).repeat(1, 2),\n",
    "        forced_prefix[:, 4:],\n",
    "    ], dim=-1),\n",
    "    decoder_attention_mask=torch.cat([\n",
    "        torch.ones_like(forced_prefix[:, :4]),\n",
    "        torch.zeros(1, 2),\n",
    "        torch.ones_like(forced_prefix[:, 4:]),\n",
    "    ], dim=-1),\n",
    "    max_length=100,\n",
    "    num_beams=5,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "print(\"PAD BETWEEN FLUFF AND PREFIX\")\n",
    "print(tokenizer.batch_decode(batch_outputs_2, skip_special_tokens=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [sample, sample] # for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_audio_signals = [\n",
    "    torchaudio.functional.resample(\n",
    "        torch.tensor(sample[\"audio\"][\"array\"]),\n",
    "        sample[\"audio\"][\"sampling_rate\"],\n",
    "        16000,\n",
    "    )\n",
    "    for sample in batch\n",
    "]\n",
    "\n",
    "# turn to mono using librosa library\n",
    "import librosa\n",
    "batch_audio_signals = [librosa.to_mono(sig.numpy()) for sig in batch_audio_signals]\n",
    "\n",
    "batch_features = torch.cat([\n",
    "    feature_extractor(sig, sampling_rate=16000, return_tensors=\"pt\")[\"input_features\"]\n",
    "    for sig in batch_audio_signals\n",
    "])\n",
    "\n",
    "assert batch_features.ndim == 3\n",
    "assert batch_features.shape[0] == len(batch)\n",
    "\n",
    "batch_labels_str = [sample[\"sentence\"] for sample in batch]\n",
    "\n",
    "#batch_prefixes_str = [\"clotho caption : \"] + [\"audioset keywords : \"]\n",
    "batch_prefixes_str = [\"This device\", \"Hello darkness my old\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This device has a cathode inside an anode wire cage.',\n",
       " 'This device has a cathode inside an anode wire cage.']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORCED PREFIXES\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|><|endoftext|><|endoftext|>This device\n",
      "attn_mask = tensor([1, 1, 1, 1, 0, 0, 1, 1])\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|>Hello darkness my old\n",
      "attn_mask = tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "label_str = 'This device has a cathode inside an anode wire cage.'\n",
      "forced_prefix_str = 'This device'\n",
      "output_str = 'This device has a cathode inside an anode wire cage.'\n",
      "\n",
      "label_str = 'This device has a cathode inside an anode wire cage.'\n",
      "forced_prefix_str = 'Hello darkness my old'\n",
      "output_str = 'Hello darkness my old friend. This device has a cathode inside an anode wire cage.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_fluff = tokenizer(\n",
    "    text_target=[\"\"] * len(batch_prefixes_str),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ")\n",
    "assert (batch_fluff[\"input_ids\"][:, -1] == tokenizer.eos_token_id).all()\n",
    "batch_fluff_input_ids = batch_fluff[\"input_ids\"][:, :-1] \n",
    "batch_fluff_attention_mask = batch_fluff[\"attention_mask\"][:, :-1]\n",
    "\n",
    "orig_padding_side = tokenizer.padding_side\n",
    "tokenizer.padding_side = \"left\"\n",
    "batch_prefixes = tokenizer(\n",
    "    text_target=batch_prefixes_str,\n",
    "    return_tensors=\"pt\",\n",
    "    add_special_tokens=False,\n",
    "    padding=True,\n",
    ")\n",
    "tokenizer.padding_side = orig_padding_side\n",
    "\n",
    "batch_prefixes_input_ids = torch.cat([batch_fluff_input_ids, batch_prefixes[\"input_ids\"]], dim=-1)\n",
    "batch_prefixes_attention_mask = torch.cat([batch_fluff_attention_mask, batch_prefixes[\"attention_mask\"]], dim=-1)\n",
    "\n",
    "\n",
    "print(\"FORCED PREFIXES\")\n",
    "for decoded, attn_mask in zip(tokenizer.batch_decode(batch_prefixes_input_ids), batch_prefixes_attention_mask):\n",
    "    print(decoded)\n",
    "    print(f\"{attn_mask = }\")\n",
    "print()\n",
    "\n",
    "batch_outputs = model.generate(\n",
    "    inputs=batch_features,\n",
    "    decoder_input_ids=batch_prefixes_input_ids,\n",
    "    decoder_attention_mask=batch_prefixes_attention_mask,\n",
    "    max_new_tokens=100,\n",
    "    num_beams=5,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "batch_outputs_str = tokenizer.batch_decode(batch_outputs, skip_special_tokens=True)\n",
    "\n",
    "for label_str, forced_prefix_str, output_str in zip(batch_labels_str, batch_prefixes_str, batch_outputs_str):\n",
    "    print(f\"{label_str = }\")\n",
    "    print(f\"{forced_prefix_str = }\")\n",
    "    print(f\"{output_str = }\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiocap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
